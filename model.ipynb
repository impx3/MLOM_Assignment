{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Preparation**"
      ],
      "metadata": {
        "id": "sTKfRu16Il7h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTg4UAC2CkuO"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the dataset to the environment\n",
        "#dataset = pd.read_csv('C:\\\\Users\\\\Laptop Outlet\\\\Downloads\\\\academic_dataset.csv')\n",
        "dataset = pd.read_csv('academic_dataset.csv')"
      ],
      "metadata": {
        "id": "o5M1mjZoCzaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking if there are any missing values\n",
        "missing_vals = dataset.isnull().sum()"
      ],
      "metadata": {
        "id": "vqV-GE7NXtze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling missing values by replacing with the first mode\n",
        "dataset.fillna(dataset.mode().iloc[0], inplace=True)\n",
        "\n",
        "#Handling missing values by replacing with forward-filling (last valid value before null)\n",
        "#dataset.fillna(method='ffill', inplace=True)"
      ],
      "metadata": {
        "id": "cYHq_rClEq8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding categorical variables with LabelEncoder()\n",
        "dataset_columns = ['gender', 'NationalITy', 'PlaceofBirth', 'StageID', 'GradeID', 'SectionID', 'Topic', 'Semester', 'Relation', 'ParentAnsweringSurvey', 'ParentschoolSatisfaction', 'StudentAbsenceDays']\n",
        "\n",
        "label = LabelEncoder()\n",
        "for column in dataset_columns:\n",
        "  dataset[column] = label.fit_transform(dataset[column])"
      ],
      "metadata": {
        "id": "kQI5E-bWFeCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting other features and target variables\n",
        "x = dataset.drop(columns = ['Class'])\n",
        "y = dataset['Class']"
      ],
      "metadata": {
        "id": "fZD6Le9LGUWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encoding the target variable after separation\n",
        "label_class = LabelEncoder()\n",
        "y = label_class.fit_transform(y)"
      ],
      "metadata": {
        "id": "JqVAAU7UG5Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling numerical features using StandardScaler\n",
        "standard_scaler = StandardScaler()\n",
        "x[['raisedhands', 'VisITedResources', 'AnnouncementsView', 'Discussion']] = standard_scaler.fit_transform(x[['raisedhands', 'VisITedResources', 'AnnouncementsView','Discussion']])"
      ],
      "metadata": {
        "id": "u0Bic9SyHxC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the dataset as training set and validation set\n",
        "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gXKIbBxwHxAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Model Design**"
      ],
      "metadata": {
        "id": "BB8R3oFBIp15"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a deep learning model\n",
        "model = models.Sequential()"
      ],
      "metadata": {
        "id": "EmS5pE39ItRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input layer\n",
        "model.add(layers.InputLayer(input_shape=(x_train.shape[1],)))"
      ],
      "metadata": {
        "id": "Vbtj3IEoItPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding the first hidden layer\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "\n",
        "#Using Dropout layer to avoid overfitting\n",
        "model.add(layers.Dropout(0.5))\n",
        "\n",
        "#Adding the second hidden layer\n",
        "model.add(layers.Dense(64, activation='relu'))"
      ],
      "metadata": {
        "id": "ugeg4iOoJo4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Output layer for classification - using softmax function\n",
        "model.add(layers.Dense(3, activation='softmax'))"
      ],
      "metadata": {
        "id": "jwk33XW1J8la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YgIbxeYnKPV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Displaying the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Zy0b5KEIKRUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Training**"
      ],
      "metadata": {
        "id": "Tdh35Kt_KfRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Implementing early stopping to avoid overfitting\n",
        "es = EarlyStopping(monitor='val_loss', patience=5)"
      ],
      "metadata": {
        "id": "ay29IcDvKRNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Experimenting with different hyperparameters\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YcV1amB4N52G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "result = model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=[es])"
      ],
      "metadata": {
        "id": "7mOcA5pfKRIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Evaluation**"
      ],
      "metadata": {
        "id": "XJPF37kvLMzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the trained model with validation set\n",
        "val_loss, v_accuracy = model.evaluate(x_val, y_val)\n",
        "print(f\"Validation Loss: {val_loss}, Validation Accuracy: {v_accuracy}\")"
      ],
      "metadata": {
        "id": "rtRzoha4K5Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making predictions\n",
        "y_prediction = model.predict(x_val)\n",
        "y_prediction_classes = y_prediction.argmax(axis=1)"
      ],
      "metadata": {
        "id": "Jw3zd7bdNP8A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification metrics (confusion matrix containing precision, recall, f1-score and support)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_val, y_prediction_classes))"
      ],
      "metadata": {
        "id": "cbGBSCLyNPrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating the accuracy\n",
        "accuracy = accuracy_score(y_val, y_prediction_classes)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "0crBmKFKN54i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}